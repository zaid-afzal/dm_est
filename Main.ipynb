{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textract import process\n",
    "text = process('./PDFs/496aadu.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------> Language :  Book\n",
      "Files at Specified Path :  1\n",
      "Total Chars :  93315\n",
      "Total Words :  15189\n",
      "----------------------------\n",
      "Unique Words :  3908\n",
      "Words\tRatio\n",
      "50 \t31.7927447495\n",
      "100 \t41.325959576\n",
      "150 \t47.4356442162\n",
      "200 \t51.8994008822\n",
      "400 \t62.6242675621\n",
      "500 \t66.0477977484\n",
      "700 \t71.2225952992\n",
      "900 \t75.1728224373\n",
      "1000 \t76.7924155639\n",
      "2000 \t87.4448614129\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def all_files(mypath):\n",
    "    ftypes = ['txt', 'srt', 'sub']\n",
    "    return [f for f in listdir(mypath) if isfile(join(mypath, f)) and f[len(f)-3:] in ftypes]\n",
    "\n",
    "def extract_words(filename):\n",
    "    with open(filename,'r') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [re.sub('[{}?.,|0-9\\-/!<>*()$&#%:\"\\'_]', ' ', line) for line in lines]\n",
    "        return ' '.join( [' '.join(line.split()) for line in lines] )\n",
    "        \n",
    "Language = \"Book\"\n",
    "print \"---------> Language : \", Language\n",
    "OutputFilename = \"1000_\" + Language + \".csv\"\n",
    "mypath = \"./\" + Language + \"/\"\n",
    "files = all_files(mypath)\n",
    "print \"Files at Specified Path : \", len(files)\n",
    "\n",
    "words_string = ' '.join( [extract_words(mypath + fname) for fname in files] )\n",
    "\n",
    "print \"Total Chars : \" , len(words_string)\n",
    "\n",
    "words_list = words_string.split(' ')\n",
    "words_list = filter(None, words_list)\n",
    "words_list = [ w.lower() for w in words_list]\n",
    "print \"Total Words : \", len(words_list)\n",
    "\n",
    "np_words = np.array(words_list)\n",
    "\n",
    "print \"----------------------------\"\n",
    "unique, counts = np.unique(np_words, return_counts=True)\n",
    "\n",
    "np_freq_array = np.asarray((unique, counts)).T\n",
    "\n",
    "print \"Unique Words : \", len(np_freq_array)\n",
    "\n",
    "words_tuples = [( item[0] , int(item[1]) ) for item in np_freq_array]\n",
    "    \n",
    "sorted_freq = sorted( words_tuples, key = lambda x : x[1], reverse=True)\n",
    "\n",
    "with open(OutputFilename,'wb') as resultFile:\n",
    "    for i in range(0, len(sorted_freq)):\n",
    "        #print sorted_freq[i][0], \" \", sorted_freq[i][1]\n",
    "        resultFile.write( sorted_freq[i][0] + \",\" + str(sorted_freq[i][1]) + \"\\n\" )\n",
    "\n",
    "count = 0\n",
    "quantity = [50,100,150,200,400,500,700,900,1000,2000,4000,8000]\n",
    "print \"Words\\tRatio\"\n",
    "for i in range(0, len(sorted_freq)):\n",
    "    count += sorted_freq[i][1]\n",
    "    if i in quantity:\n",
    "        ratio = (count/float(len(np_words))) * 100\n",
    "        print  i ,\"\\t\", ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------> Language :  PDFs\n",
      "Files at Specified Path :  7\n",
      "Total Chars :  3047911\n",
      "Total Words :  448679\n",
      "----------------------------\n",
      "Unique Words :  14374\n",
      "Words\tRatio\n",
      "50 \t30.0528885907\n",
      "100 \t37.4120473657\n",
      "150 \t42.044089427\n",
      "200 \t45.5746758819\n",
      "400 \t54.068053107\n",
      "500 \t56.8279326646\n",
      "700 \t60.9498104435\n",
      "900 \t63.9920745121\n",
      "1000 \t65.2604646083\n",
      "2000 \t73.6742749271\n",
      "4000 \t81.9383122455\n",
      "8000 \t90.0572569699\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from textract import process\n",
    "\n",
    "def all_files(mypath):\n",
    "    ftypes = ['pdf','txt']\n",
    "    return [f for f in listdir(mypath) if isfile(join(mypath, f)) and f[len(f)-3:] in ftypes]\n",
    "\n",
    "def extract_words(filename):\n",
    "    text = process('./PDFs/496aadu.pdf')\n",
    "    lines = text.split('\\n')\n",
    "    lines = [re.sub('[{}?.,|0-9\\-/!<>*()$&#%:\"\\'_]', ' ', line) for line in lines]\n",
    "    return ' '.join( [' '.join(line.split()) for line in lines] )\n",
    "        \n",
    "Language = \"PDFs\"\n",
    "print \"---------> Language : \", Language\n",
    "OutputFilename = \"1000_\" + Language + \".csv\"\n",
    "mypath = \"./\" + Language + \"/\"\n",
    "files = all_files(mypath)\n",
    "print \"Files at Specified Path : \", len(files)\n",
    "\n",
    "words_string = ' '.join( [extract_words(mypath + fname) for fname in files] )\n",
    "\n",
    "print \"Total Chars : \" , len(words_string)\n",
    "\n",
    "words_list = words_string.split(' ')\n",
    "words_list = filter(None, words_list)\n",
    "words_list = [ w.lower() for w in words_list]\n",
    "print \"Total Words : \", len(words_list)\n",
    "\n",
    "np_words = np.array(words_list)\n",
    "\n",
    "print \"----------------------------\"\n",
    "unique, counts = np.unique(np_words, return_counts=True)\n",
    "\n",
    "np_freq_array = np.asarray((unique, counts)).T\n",
    "\n",
    "print \"Unique Words : \", len(np_freq_array)\n",
    "\n",
    "words_tuples = [( item[0] , int(item[1]) ) for item in np_freq_array]\n",
    "    \n",
    "sorted_freq = sorted( words_tuples, key = lambda x : x[1], reverse=True)\n",
    "\n",
    "with open(OutputFilename,'wb') as resultFile:\n",
    "    for i in range(0, len(sorted_freq)):\n",
    "        #print sorted_freq[i][0], \" \", sorted_freq[i][1]\n",
    "        resultFile.write( sorted_freq[i][0] + \",\" + str(sorted_freq[i][1]) + \"\\n\" )\n",
    "\n",
    "count = 0\n",
    "quantity = [50,100,150,200,400,500,700,900,1000,2000,4000,8000]\n",
    "print \"Words\\tRatio\"\n",
    "for i in range(0, len(sorted_freq)):\n",
    "    count += sorted_freq[i][1]\n",
    "    if i in quantity:\n",
    "        ratio = (count/float(len(np_words))) * 100\n",
    "        print  i ,\"\\t\", ratio"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
